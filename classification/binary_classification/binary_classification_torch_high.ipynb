{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/binary_classification.csv\")\n",
    "\n",
    "x = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "x_ssc = StandardScaler()\n",
    "x_scaled = x_ssc.fit_transform(x)\n",
    "\n",
    "x_scaled_tensor = torch.tensor(x_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).reshape(-1,1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled_tensor, y_tensor, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(30,1),\n",
    "    nn.Sigmoid()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  100/2000 Loss: nan\n",
      "Epoch  200/2000 Loss: nan\n",
      "Epoch  300/2000 Loss: nan\n",
      "Epoch  400/2000 Loss: nan\n",
      "Epoch  500/2000 Loss: nan\n",
      "Epoch  600/2000 Loss: nan\n",
      "Epoch  700/2000 Loss: nan\n",
      "Epoch  800/2000 Loss: nan\n",
      "Epoch  900/2000 Loss: nan\n",
      "Epoch 1000/2000 Loss: nan\n",
      "Epoch 1100/2000 Loss: nan\n",
      "Epoch 1200/2000 Loss: nan\n",
      "Epoch 1300/2000 Loss: nan\n",
      "Epoch 1400/2000 Loss: nan\n",
      "Epoch 1500/2000 Loss: nan\n",
      "Epoch 1600/2000 Loss: nan\n",
      "Epoch 1700/2000 Loss: nan\n",
      "Epoch 1800/2000 Loss: nan\n",
      "Epoch 1900/2000 Loss: nan\n"
     ]
    }
   ],
   "source": [
    "epochs = 2000\n",
    "optimizer=optim.SGD(model.parameters(),lr=1e-2)\n",
    "\n",
    "for epoch in range(1,epochs):\n",
    "    y_pred = model(x_train)\n",
    "\n",
    "    loss = F.binary_cross_entropy(y_pred, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Loss: {:.6f}'.format(\n",
    "            epoch, epochs, loss.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/torch/lib/python3.10/site-packages/sklearn/utils/multiclass.py:380: RuntimeWarning: invalid value encountered in cast\n",
      "  if xp.any(data != data.astype(int)):\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y_true contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m accuracy_score(y_pred\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mnumpy(),y_test)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:192\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m validate_parameter_constraints(\n\u001b[1;32m    188\u001b[0m     parameter_constraints, params, caller_name\u001b[39m=\u001b[39mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    191\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    193\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    194\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    199\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    200\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    201\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    202\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:221\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    222\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    223\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:87\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[39mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39my_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m---> 87\u001b[0m type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my_true\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     88\u001b[0m type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     90\u001b[0m y_type \u001b[39m=\u001b[39m {type_true, type_pred}\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch/lib/python3.10/site-packages/sklearn/utils/multiclass.py:381\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    379\u001b[0m     data \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mdata \u001b[39mif\u001b[39;00m issparse(y) \u001b[39melse\u001b[39;00m y\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39many(data \u001b[39m!=\u001b[39m data\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)):\n\u001b[0;32m--> 381\u001b[0m         _assert_all_finite(data, input_name\u001b[39m=\u001b[39;49minput_name)\n\u001b[1;32m    382\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcontinuous\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m suffix\n\u001b[1;32m    384\u001b[0m \u001b[39m# Check multiclass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch/lib/python3.10/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input y_true contains NaN."
     ]
    }
   ],
   "source": [
    "accuracy_score(y_pred.detach().numpy(),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
